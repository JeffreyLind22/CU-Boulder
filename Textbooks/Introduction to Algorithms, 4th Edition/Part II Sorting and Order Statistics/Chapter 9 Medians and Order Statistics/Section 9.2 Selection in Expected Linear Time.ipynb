{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Introduction to Algorithms, 4th Edition: Part II Sorting and Order Statistics - Chapter 9 Medians and Order Statistics - Section 9.2 Selection in Expected Linear Time",
   "id": "2096460d68234c7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The general selection problem - finding the $i$th order statistic for any value of $i$ - appears more difficult than the simple problem of finding a minimum. Yet surprisingly, the asymptotic running time for both problems is the same: $\\Theta(n)$. This section presents a divide-and-conquer algorithm for the selection problem. The algorithm $\\texttt{Randomized-Select}$ is modeled after the quicksort algorithm of Chapter 7. Like quicksort, it partitions the input array recursively. But unlike quicksort, which recursively processes both sides of the partition, $\\texttt{Randomized-Select}$ works on only one side of the partition. This difference shows up in the analysis: whereas quicksort has an expected running time of $\\Theta(n\\lg{n})$, the expected running time of $\\texttt{Randomized-Select}$ is $\\Theta(n)$, assuming that the elements are distinct.\n",
    "\n",
    "The $\\texttt{Randomized-Select}$ procedure uses the procedure $\\texttt{Randomized-Partition}$ introduced in Section 7.3. Like $\\texttt{Randomized-Quicksort}$, it is a randomized algorithm, since its behavior is determined in part by the output of a random-number generator. The $\\texttt{Randomized-Select}$ procedure returns the $i$th smallest element of the array $A[p : r]$, where $1 \\leq i \\leq r - p + 1$.\n",
    "\n",
    "```\n",
    "Randomized-Select(A, p, r, i)\n",
    "[1] if p == r\n",
    "[2]     return A[p] // 1 <= i <= r - p + 1 when p == r means that i = 1\n",
    "[3] q = Randomized-Partition(A, p, r)\n",
    "[4] k = q - p + 1\n",
    "[5] if i == k\n",
    "[6]     return A[q] // The pivot value is the answer\n",
    "[7] elsif i < k\n",
    "[8]     return Randomized-Select(A, p, q - 1, i)\n",
    "[9] else return Randomized-Select(A, q + 1, r, i - k)\n",
    "```\n",
    "\n",
    "Figure 9.1 illustrates how the $\\texttt{Randomized-Select}$ procedure works. Line $1$ checks for the base case of the recursion, in which the subarray $A[p : r]$ consists of just one element. In this case, $i$ must equal $1$, and line $2$ simply returns $A[p]$ as the $i$th smallest element. Otherwise, the call to $\\texttt{Randomized-Partition}$ in line 3 partitions the array $A[p : r]$ into two (possibly empty) subarrays $A[p : q - 1]$ and $A[q + 1 : r]$ such that each element of $A[p : q - 1]$ is less than or equal to $A[q]$, which in turn is less than each element of $A[q + 1 : r]$. (Although our analysis assumes that the elements are distinct, the procedure still yields the correct result even if equal elements are present.) As in quicksort, we'll refer to $A[q]$ as the ***pivot*** element. Line $4$ computes the number $k$ of elements in the subarray $A[p : q]$, that is, the number of elements in the low side of the partition, plus $1$ for the pivot element. Line $5$ then checks whether $A[q]$ is the $i$th smallest element. If it is, then line $6$ returns $A[q]$. Otherwise, the algorithm determines in which of the two subarrays $A[p : q - 1]$ and $A[q + 1 : r]$ the $i$th smallest element lies. If $i < k$, then the desired element lies on the low side of the partition, and line $8$ recursively selects it from the subarray. If $i > k$, however, then the desired element lies on the high side of the partition. Since we already know $k$ values that are smaller than the $i$th smallest element of $A[p : r]$ - namely, the elements of $A[p : q]$ - the desired element is the $(i - k)$th smallest element of $A[q + 1 : r]$, which line $9$ finds recursively. The code appears to allow recursive calls to subarrays with $0$ elements, but this situation cannot happen.\n",
    "\n",
    "<img src=\"Figure 9.1.png\" alt=\"Figure 9.1\" width=\"500\"/>\n",
    "\n",
    "The worst-case running time for $\\texttt{Randomized-Select}$ is $\\Theta\\left(n^2\\right)$, even to find the minimum, because it would be extremely unlucky and always partition around the largest remaining element before identifying the $i$th smallest when only one element remains. In this worst case, each recursive step removes only the pivot from consideration. Because partitioning $n$ elements takes $\\Theta(n)$ time, the recurrence for the worst-case running time is the same as for $\\texttt{Quicksort}$: $T(n) = T(n - 1) + \\Theta(n)$, with the solution $T(n) = \\Theta\\left(n^2\\right)$. We'll see that the algorithm has a linear expected running time, however, and because it is randomized, no particular input elicits the worst-case behavior.\n",
    "\n",
    "To see the intuition behind the linear expected running time, suppose that each time the algorithm randomly selects a pivot element, the pivot lies somewhere within the second and third quartiles - the \"middle half\" - of the remaining elements in sorted order. If the $i$th smallest element is less than the pivot, then all the elements greater than the pivot are ignored in all future recursive calls. These ignored elements include at least the uppermost quartile, and possibly more. Likewise, if the $i$th smallest element is greater than the pivot, then all the elements less than the pivot - at least the first quartile - are ignored in all future recursive calls. Either way, therefore, at least $\\frac{1}{4}$ of the remaining elements are ignored in all future recursive calls, leaving at most $\\frac{3}{4}$ of the remaining elements ***in play***: residing in the subarray $A[p : r]$. Since $\\texttt{Randomized-Partition}$ takes $\\Theta(n)$ time on a subarray of $n$ elements, the recurrence for the worst-case running time is $T(n) = T\\left(\\frac{3n}{4}\\right) + \\Theta(n)$. By case $3$ of the master method (Theorem 4.1), this recurrence has the solution $T(n) = \\Theta(n)$.\n",
    "\n",
    "Of course, the pivot does not necessarily fall into the middle half every time. Since the pivot is selected at random, the probability that it falls into the middle is about $\\frac{1}{2}$ each time. We can view the process of selecting the pivot as a Bernoulli trial (see Section C.4) with success equating to the pivot residing in the middle half. Thus, the expected number of trials needed for success is given by a geometric distribution: just two trials on average (equation (C.36)). In other words, we expect that half of the partitionings reduce the number of elements still in play by at least $\\frac{3}{4}$ and that half of the partitionings do not help as much. Consequently, the expected number of partitionings at most doubles from the case when the pivot always falls into the middle half. The cost of each extra partitioning is less than the one that preceded it, so that the expected running time is still $\\Theta(n)$.\n",
    "\n",
    "To make the above argument rigorous, we start by defining the random variable $A^{(j)}$ as the set of elements of $A$ that are still in play after $j$ partitionings (that is, within the subarray $A[p : r]$ after $j$ calls to $\\texttt{Randomized-Select}$), so that $A^{(0)}$ consists of all the elements in $A$. Since each partitioning removes at least one element - the pivot - from being in play, the sequence $\\left|A^{(0)}\\right|, \\left|A^{(1)}\\right|, \\left|A^{(2)}\\right|, \\ldots$ strictly decreases. Set $A^{(j - 1)}$ is in play before the $j$th partitioning, and set $A^{(j)}$ remains in play afterward. For convenience, assume that the initial set $A^{(0)}$ is the result of a $0$th \"dummy\" partitioning.\n",
    "\n",
    "Let's call the $i$th partitioning ***helpful*** if $\\left|A^{(j)}\\right| \\leq \\frac{3}{4}\\left|A^{(j - 1)}\\right|$. Figure 9.1 shows the sets $A^{(j)}$ and whether partitionings are helpful for an example array. A helpful partitioning corresponds to a successful Bernoulli trial. The following lemma shows that a partitioning is at least as likely to be helpful as not."
   ],
   "id": "1152828a1a56aa2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## *Lemma 9.1*\n",
    "A partitioning is helpful with the probability of at least $\\frac{1}{2}$.\n",
    "\n",
    "***Proof*** Whether a partitioning is helpful depends on the randomly chosen pivot. We discussed the \"middle half\" in the informal argument above Let's more precisely define the middle half of an $n$-element subarray as all but the smallest $\\left\\lceil \\frac{n}{4} \\right\\rceil - 1$ and greatest $\\left\\lceil \\frac{n}{4} \\right\\rceil - 1$ elements (that is, all but the first $\\left\\lceil \\frac{n}{4} \\right\\rceil - 1$ and last $\\left\\lceil \\frac{n}{4} \\right\\rceil - 1$ elements if the subarray were sorted). We'll prove that if the pivot falls into the middle half, then the pivot leads to a helpful partitioning, and we'll also prove that the probability of the pivot falling into the middle half is at least $\\frac{1}{2}$.\n",
    "\n",
    "Regardless of where the pivot falls, either all the elements greater than it or all the elements less than it, along with the pivot itself, will no longer be in play after partitioning. If the pivot falls into the middle half, therefore, at least $\\left\\lceil \\frac{n}{4} \\right\\rceil - 1$ elements less than the pivot or $\\left\\lceil \\frac{n}{4} \\right\\rceil - 1$ elements greater than the pivot, pus the pivot, will no longer be in play. The number of elements remaining in play will be at most $n - \\left\\lceil \\frac{n}{4} \\right\\rceil$, which equals $\\left\\lfloor \\frac{3n}{4} \\right\\rfloor$ by Exercise 3.3-2. Since $\\left\\lfloor \\frac{3n}{4} \\right\\rfloor \\leq \\frac{3n}{4}$, the partitioning is helpful.\n",
    "\n",
    "To determine a lower bound on the probability that a randomly chosen pivot falls into the middle half, we determine an upper bound on the probability that it does not. The probability is\n",
    "$$\n",
    "\\frac{2\\left(\\left\\lceil \\frac{n}{4} \\right\\rceil - 1\\right)}{n} \\leq \\frac{2\\left(\\left(\\frac{n}{4} + 1\\right) - 1\\right)}{n} = \\frac{\\frac{n}{2}}{n} = \\frac{1}{2}.\n",
    "$$\n",
    "Thus, the pivot has a probability of at least $\\frac{1}{2}$ of falling into the middle half, and so the probability is at least $\\frac{1}{2}$ that a partitioning is helpful. \n",
    "\n",
    "<div style=\"text-align: right\"> $\\blacksquare$ </div>"
   ],
   "id": "1bfa0857aed8bd86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can now bound the expected running time of $\\texttt{Randomized-Select}$.",
   "id": "b5190131fe7eb870"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## *Theorem 9.2*\n",
    "The procedure $\\texttt{Randomized-Select}$ on an input array of $n$ distinct elements has an expected running time of $\\Theta(n)$."
   ],
   "id": "17e11b858d6b4a88"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
